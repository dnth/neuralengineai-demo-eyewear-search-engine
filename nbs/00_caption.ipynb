{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adbc23f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Load the latest Moondream2 model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"vikhyatk/moondream2\",\n",
    "    revision=\"2025-06-21\",\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vikhyatk/moondream2\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7f1d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "dataset = load_dataset(\"Adi-0-0-Gupta/Eyewear-Dataset-1024\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2edd2545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset['train'].select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b044790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b87a9605cf24783b4f412c491bbe5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding captions:   0%|          | 0/20964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with captions:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['brand', 'prompt', 'product_type', 'image', 'control_image', 'caption'],\n",
      "        num_rows: 20964\n",
      "    })\n",
      "})\n",
      "\n",
      "Sample caption:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Invalid key: 0. Please first select a split. For example: `my_dataset_dictionary['train'][0]`. Available splits: ['train']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(dataset_with_captions)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSample caption:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdataset_with_captions\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mcaption\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/neuralengineai-demo-eyewear-search-engine/.venv/lib/python3.12/site-packages/datasets/dataset_dict.py:88\u001b[39m, in \u001b[36mDatasetDict.__getitem__\u001b[39m\u001b[34m(self, k)\u001b[39m\n\u001b[32m     84\u001b[39m available_suggested_splits = [\n\u001b[32m     85\u001b[39m     split \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m (Split.TRAIN, Split.TEST, Split.VALIDATION) \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m     86\u001b[39m ]\n\u001b[32m     87\u001b[39m suggested_split = available_suggested_splits[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m available_suggested_splits \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m     89\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Please first select a split. For example: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     90\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`my_dataset_dictionary[\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggested_split\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m][\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]`. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAvailable splits: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     92\u001b[39m )\n",
      "\u001b[31mKeyError\u001b[39m: \"Invalid key: 0. Please first select a split. For example: `my_dataset_dictionary['train'][0]`. Available splits: ['train']\""
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def caption_batch(batch):\n",
    "    \"\"\"\n",
    "    Function to caption a batch of images from the dataset\n",
    "    \"\"\"\n",
    "    captions = []\n",
    "    \n",
    "    for image in batch[\"image\"]:  # Process each image in the batch\n",
    "        try:\n",
    "            # If image is a path string, load it\n",
    "            if isinstance(image, str):\n",
    "                image = Image.open(image)\n",
    "                image = model.encode(image)\n",
    "            \n",
    "            # Generate caption using Moondream2\n",
    "            caption_result = model.caption(image, length=\"normal\")\n",
    "            captions.append(caption_result[\"caption\"])\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Handle any errors gracefully\n",
    "            captions.append(f\"Error generating caption: {str(e)}\")\n",
    "    \n",
    "    # Return the batch with new caption column\n",
    "    batch[\"caption\"] = captions\n",
    "    return batch\n",
    "\n",
    "# Apply the captioning function using batched map\n",
    "dataset_with_captions = dataset.map(\n",
    "    caption_batch,\n",
    "    batched=True,           # Enable batch processing\n",
    "    batch_size=20,           # Process 8 images at a time (adjust based on your GPU memory)\n",
    "    num_proc=1,             # Use single process to avoid GPU memory conflicts\n",
    "    desc=\"Adding captions\"\n",
    ")\n",
    "\n",
    "print(\"Dataset with captions:\")\n",
    "print(dataset_with_captions)\n",
    "print(\"\\nSample caption:\")\n",
    "print(dataset_with_captions[0][\"caption\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e6db672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brand': 'Polaroid',\n",
       " 'prompt': 'shape is round / oval, technology is r, frame material is polycarbonate,.',\n",
       " 'product_type': 'sunglasses',\n",
       " 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024>,\n",
       " 'control_image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024>,\n",
       " 'caption': 'A close-up view of a pair of Polaroid sunglasses. The frame is a dark brown color with a tortoiseshell pattern and a slightly curved shape. The clear lenses reflect a blue tint. The right arm of the sunglasses is slightly extended, showcasing the sleek design. The brand name \"Polaroid\" is prominently displayed on the right arm of the frame. Two small white dots are visible on the left arm, possibly indicating fasteners. The sunglasses are set against a stark white background, which highlights their features and design.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_with_captions['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2655456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b807ab0c39f4bc3bd8fdef35e45592a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/5 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24be4aa3095b43cb9c9c65c950347913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4193 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5e73f5ae04459ba45f3d10960db05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/42 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f0fccb1e284c59a2f497f3f11c6e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4193 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7d6bbff96647d1979620fb766cbb2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/42 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9562773a6d6b4c248dd635d3f71925af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4193 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74051925756d40b0ab32d05d7fc83a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/42 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03405987ee2744e5aa747d8d2bb4572b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4193 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f83649ca484bd7916bad93df90bff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/42 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804e60750a0c4686a4e42ebababe27c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a81ae8313646dd9ec09488b3fcbcb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/42 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/dnth/Eyewear-Dataset-1024-with-captions/commit/66a3b52eb9ea141d7408e73a9cada86ae5775e9a', commit_message='Upload dataset', commit_description='', oid='66a3b52eb9ea141d7408e73a9cada86ae5775e9a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/dnth/Eyewear-Dataset-1024-with-captions', endpoint='https://huggingface.co', repo_type='dataset', repo_id='dnth/Eyewear-Dataset-1024-with-captions'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_with_captions.push_to_hub(\"dnth/Eyewear-Dataset-1024-with-captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f853085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
